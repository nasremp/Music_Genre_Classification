{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Music Genre Classification","metadata":{}},{"cell_type":"markdown","source":"**Import libraries**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport glob\nimport os\nimport PIL\nimport tensorflow as tf\nimport cv2\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications import EfficientNetB0, EfficientNetB3, MobileNetV2, InceptionV3, ResNet152V2\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:06.961264Z","iopub.execute_input":"2022-06-26T01:35:06.961638Z","iopub.status.idle":"2022-06-26T01:35:06.969072Z","shell.execute_reply.started":"2022-06-26T01:35:06.961606Z","shell.execute_reply":"2022-06-26T01:35:06.968076Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Get data","metadata":{}},{"cell_type":"code","source":"img_data = '../input/gtzan-dataset-music-genre-classification/Data/images_original/'","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:17.860876Z","iopub.execute_input":"2022-06-26T01:35:17.861233Z","iopub.status.idle":"2022-06-26T01:35:17.865201Z","shell.execute_reply.started":"2022-06-26T01:35:17.861203Z","shell.execute_reply":"2022-06-26T01:35:17.864191Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"### Data Loader","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE=8\nTARGET_SIZE=224 # Based on keras pew-trained models\nNUM_CLASSES=10","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:17.866572Z","iopub.execute_input":"2022-06-26T01:35:17.867082Z","iopub.status.idle":"2022-06-26T01:35:17.877095Z","shell.execute_reply.started":"2022-06-26T01:35:17.867050Z","shell.execute_reply":"2022-06-26T01:35:17.876263Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"train_ds = image_dataset_from_directory(\n  img_data,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=99,\n  image_size=(TARGET_SIZE, TARGET_SIZE),\n  batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:17.879074Z","iopub.execute_input":"2022-06-26T01:35:17.879723Z","iopub.status.idle":"2022-06-26T01:35:18.059173Z","shell.execute_reply.started":"2022-06-26T01:35:17.879678Z","shell.execute_reply":"2022-06-26T01:35:18.058456Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"val_ds = image_dataset_from_directory(\n  img_data,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=99,\n  image_size=(TARGET_SIZE, TARGET_SIZE),\n  batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:22.845479Z","iopub.execute_input":"2022-06-26T01:35:22.846003Z","iopub.status.idle":"2022-06-26T01:35:23.013491Z","shell.execute_reply.started":"2022-06-26T01:35:22.845959Z","shell.execute_reply":"2022-06-26T01:35:23.012462Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:23.015483Z","iopub.execute_input":"2022-06-26T01:35:23.016092Z","iopub.status.idle":"2022-06-26T01:35:23.021370Z","shell.execute_reply.started":"2022-06-26T01:35:23.016046Z","shell.execute_reply":"2022-06-26T01:35:23.020244Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#GTZAN Dataset tags\nTAGS = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\nTAGS_CODES = dict()\ni = 0\nfor tag in TAGS:\n    i+=1\n    TAGS_CODES[tag] = i\n# data = pd.DataFrame(columns=[\"img\", \"class\"])\nDATADIR = \"../input/gtzan-dataset-music-genre-classification/Data/images_original\"\nX = []\nY = []\nfor tag in TAGS:\n    path = os.path.join(DATADIR, tag)\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path, img))\n        new_data = dict()\n        X.append( img_array)\n        Y.append( TAGS_CODES[tag])\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:23.023074Z","iopub.execute_input":"2022-06-26T01:35:23.023554Z","iopub.status.idle":"2022-06-26T01:35:27.226158Z","shell.execute_reply.started":"2022-06-26T01:35:23.023511Z","shell.execute_reply":"2022-06-26T01:35:27.225320Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# The dataset content is consists out:\n1- genres original - A collection of 10 genres with 100 audio files each, all having a length of 30 seconds (the famous GTZAN dataset, the MNIST of sounds)                                                                                   \n2- images original - A visual representation for each audio file. One way to classify data is through neural networks. Because NNs (like CNN, what we will be using today) usually take in some sort of image representation, the audio files were converted to Mel Spectrograms to make this possible.                                                                \nWe will use image original folder\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(25, 25))\nfor i in range(8):\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(X[i].astype(\"uint8\"))\n    plt.axis(\"off\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:47.243257Z","iopub.execute_input":"2022-06-26T01:35:47.243981Z","iopub.status.idle":"2022-06-26T01:35:47.825182Z","shell.execute_reply.started":"2022-06-26T01:35:47.243928Z","shell.execute_reply":"2022-06-26T01:35:47.824386Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## Callbacks and Helper Functions","metadata":{}},{"cell_type":"code","source":"model_save = tf.keras.callbacks.ModelCheckpoint('./best_weights.h5', \n                             save_best_only = True, \n                             save_weights_only = True,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n                           patience = 10, mode = 'min', verbose = 1,\n                           restore_best_weights = True)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n                              patience = 2, min_delta = 0.001, \n                              mode = 'min', verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:47.826735Z","iopub.execute_input":"2022-06-26T01:35:47.827238Z","iopub.status.idle":"2022-06-26T01:35:47.833995Z","shell.execute_reply.started":"2022-06-26T01:35:47.827205Z","shell.execute_reply":"2022-06-26T01:35:47.833229Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def plot_hist(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    plt.figure(figsize=(10, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(acc, label='Training Accuracy')\n    plt.plot(val_acc, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n    plt.grid()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(loss, label='Training Loss')\n    plt.plot(val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.grid()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:47.835183Z","iopub.execute_input":"2022-06-26T01:35:47.835678Z","iopub.status.idle":"2022-06-26T01:35:47.851480Z","shell.execute_reply.started":"2022-06-26T01:35:47.835646Z","shell.execute_reply":"2022-06-26T01:35:47.850275Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Shuffle Data and Image  (discard)","metadata":{}},{"cell_type":"code","source":"# numpy.array([1.2, \"abc\"], dtype=float)\nX =  np.array(X)\nY = np.array(Y)\nX = X/255\nX_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:47.852526Z","iopub.execute_input":"2022-06-26T01:35:47.852940Z","iopub.status.idle":"2022-06-26T01:35:51.135702Z","shell.execute_reply.started":"2022-06-26T01:35:47.852903Z","shell.execute_reply":"2022-06-26T01:35:51.134666Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(TARGET_SIZE, TARGET_SIZE, 3)),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(NUM_CLASSES)\n])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:51.138789Z","iopub.execute_input":"2022-06-26T01:35:51.139087Z","iopub.status.idle":"2022-06-26T01:35:51.215432Z","shell.execute_reply.started":"2022-06-26T01:35:51.139058Z","shell.execute_reply":"2022-06-26T01:35:51.214307Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(lr = 0.001),\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:51.217123Z","iopub.execute_input":"2022-06-26T01:35:51.217418Z","iopub.status.idle":"2022-06-26T01:35:51.231152Z","shell.execute_reply.started":"2022-06-26T01:35:51.217389Z","shell.execute_reply":"2022-06-26T01:35:51.230263Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:51.232268Z","iopub.execute_input":"2022-06-26T01:35:51.232679Z","iopub.status.idle":"2022-06-26T01:35:51.250617Z","shell.execute_reply.started":"2022-06-26T01:35:51.232650Z","shell.execute_reply":"2022-06-26T01:35:51.249866Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"epochs=15\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n  callbacks=[model_save, early_stop, reduce_lr],\n  verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:35:51.253295Z","iopub.execute_input":"2022-06-26T01:35:51.253965Z","iopub.status.idle":"2022-06-26T01:40:49.070619Z","shell.execute_reply.started":"2022-06-26T01:35:51.253908Z","shell.execute_reply":"2022-06-26T01:40:49.069679Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"plot_hist(history)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:40:49.072059Z","iopub.execute_input":"2022-06-26T01:40:49.072376Z","iopub.status.idle":"2022-06-26T01:40:49.394616Z","shell.execute_reply.started":"2022-06-26T01:40:49.072347Z","shell.execute_reply":"2022-06-26T01:40:49.393765Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"### **We notice that the validation loss in first 3 epochs is improving. Val accuracy is about 50 %. With number of epochs increased val accuracy goes for 62 % . However, val_loss did not improve from 1.30901. call-back function that reduces learning rate is called. Best Val accuracy = 64 % while training accuracy near 100% (over fit)**","metadata":{}},{"cell_type":"markdown","source":"### **Dropout Is A soltion for Overfitting**","metadata":{}},{"cell_type":"markdown","source":"## CNN with Dropout","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(TARGET_SIZE, TARGET_SIZE, 3)),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.4),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.4),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.4),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(NUM_CLASSES)\n])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:40:49.396023Z","iopub.execute_input":"2022-06-26T01:40:49.396341Z","iopub.status.idle":"2022-06-26T01:40:49.506545Z","shell.execute_reply.started":"2022-06-26T01:40:49.396303Z","shell.execute_reply":"2022-06-26T01:40:49.505724Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(lr = 0.001),\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:40:49.508200Z","iopub.execute_input":"2022-06-26T01:40:49.508818Z","iopub.status.idle":"2022-06-26T01:40:49.523442Z","shell.execute_reply.started":"2022-06-26T01:40:49.508770Z","shell.execute_reply":"2022-06-26T01:40:49.522677Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:40:49.524705Z","iopub.execute_input":"2022-06-26T01:40:49.525348Z","iopub.status.idle":"2022-06-26T01:40:49.536401Z","shell.execute_reply.started":"2022-06-26T01:40:49.525302Z","shell.execute_reply":"2022-06-26T01:40:49.535030Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"epochs = 15\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n  callbacks=[model_save, early_stop, reduce_lr],\n  verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:40:49.537746Z","iopub.execute_input":"2022-06-26T01:40:49.538599Z","iopub.status.idle":"2022-06-26T01:46:36.415004Z","shell.execute_reply.started":"2022-06-26T01:40:49.538562Z","shell.execute_reply":"2022-06-26T01:46:36.413945Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"plot_hist(history)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T01:46:36.418937Z","iopub.execute_input":"2022-06-26T01:46:36.419306Z","iopub.status.idle":"2022-06-26T01:46:36.755908Z","shell.execute_reply.started":"2022-06-26T01:46:36.419263Z","shell.execute_reply":"2022-06-26T01:46:36.754994Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"### **Also after drop-out, the same problem of overfitting still exists. The accuracy increased a little bit in range 60 % after adding three droput layers. We need a new soltion for this since the problem appeared because of the small data set amount. So, Trransfer learning will be used to use a pre-trained model.**","metadata":{}},{"cell_type":"markdown","source":"### 1. ResNet152V2 took a lot of time before it completes its first epoch.\n### 2. I tried both of InceptionV3 and MobileNetV2 in a separate notebook. I found that InceptionV3 is better than MobileNetV2.","metadata":{}},{"cell_type":"markdown","source":"# Transfer learning - InceptionV3","metadata":{}},{"cell_type":"code","source":"def create_model():\n    conv_base = InceptionV3(include_top = False, weights = \"../input/keras-pretrained-models/InceptionV3_NoTop_ImageNet.h5\",\n                               input_shape = (TARGET_SIZE, TARGET_SIZE, 3))\n    model = conv_base.output\n    model = layers.GlobalAveragePooling2D()(model)\n    model = layers.Dense(NUM_CLASSES, activation = \"softmax\")(model)\n    model = models.Model(conv_base.input, model)\n\n    model.compile(optimizer = Adam(lr = 0.001),\n                  loss = \"sparse_categorical_crossentropy\",\n                  metrics = [\"accuracy\"])\n    return model\nINCmodel = create_model()\n#INCmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T02:13:42.446825Z","iopub.execute_input":"2022-06-26T02:13:42.447230Z","iopub.status.idle":"2022-06-26T02:13:47.082465Z","shell.execute_reply.started":"2022-06-26T02:13:42.447186Z","shell.execute_reply":"2022-06-26T02:13:47.081610Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"epochs = 15\nhistory = INCmodel.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n  callbacks=[model_save, early_stop, reduce_lr],\n  verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T02:13:55.439328Z","iopub.execute_input":"2022-06-26T02:13:55.439713Z","iopub.status.idle":"2022-06-26T03:05:22.027613Z","shell.execute_reply.started":"2022-06-26T02:13:55.439681Z","shell.execute_reply":"2022-06-26T03:05:22.026793Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"plot_hist(history)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:06:13.347608Z","iopub.execute_input":"2022-06-26T03:06:13.348046Z","iopub.status.idle":"2022-06-26T03:06:13.669763Z","shell.execute_reply.started":"2022-06-26T03:06:13.348011Z","shell.execute_reply":"2022-06-26T03:06:13.668855Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"### Validation Accuracy is around 73 %","metadata":{}},{"cell_type":"markdown","source":"# Transfer learning - EfficientNetB0","metadata":{}},{"cell_type":"code","source":"def create_model():\n    conv_base = EfficientNetB0(include_top = False, weights = \"../input/keras-pretrained-models/EfficientNetB0_NoTop_ImageNet.h5\", drop_connect_rate=0.7,\n                               input_shape = (TARGET_SIZE, TARGET_SIZE, 3))\n    model = conv_base.output\n    model = layers.GlobalAveragePooling2D()(model)\n    model = layers.Dense(NUM_CLASSES, activation = \"softmax\")(model)\n    model = models.Model(conv_base.input, model)\n\n    model.compile(optimizer = Adam(lr = 0.001),\n                  loss = \"sparse_categorical_crossentropy\",\n                  metrics = [\"accuracy\"])\n    return model\nmodel = create_model()\n#model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:06:25.607861Z","iopub.execute_input":"2022-06-26T03:06:25.608225Z","iopub.status.idle":"2022-06-26T03:06:28.485476Z","shell.execute_reply.started":"2022-06-26T03:06:25.608193Z","shell.execute_reply":"2022-06-26T03:06:28.484521Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"epochs = 15\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n  callbacks=[model_save, early_stop, reduce_lr],\n  verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:09:18.664950Z","iopub.execute_input":"2022-06-26T03:09:18.665306Z","iopub.status.idle":"2022-06-26T03:38:20.333963Z","shell.execute_reply.started":"2022-06-26T03:09:18.665276Z","shell.execute_reply":"2022-06-26T03:38:20.333039Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"plot_hist(history)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:38:45.919550Z","iopub.execute_input":"2022-06-26T03:38:45.920080Z","iopub.status.idle":"2022-06-26T03:38:46.255993Z","shell.execute_reply.started":"2022-06-26T03:38:45.920043Z","shell.execute_reply":"2022-06-26T03:38:46.255074Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"# **Best Validation accuracy 80 %**","metadata":{}},{"cell_type":"markdown","source":"## EfficientNetB0 with these custumization is better in our case than InceptionV3 & MobilNetV2 models","metadata":{}},{"cell_type":"markdown","source":"## Transfer learning - EfficientNetB0 (the usual way of transfer learning)","metadata":{}},{"cell_type":"code","source":"def create_model():\n    conv_base = EfficientNetB0(include_top = False, weights = \"../input/keras-pretrained-models/EfficientNetB0_NoTop_ImageNet.h5\", drop_connect_rate=0.6,\n                               input_shape = (TARGET_SIZE, TARGET_SIZE, 3))\n    # Freeze pre-trained layers\n    conv_base.trainable = False\n    \n    # Re-build top layers\n    model = conv_base.output\n    model = layers.GlobalAveragePooling2D()(model)\n    model = layers.BatchNormalization()(model)\n    \n    dropout_rate=0.3\n    model = layers.Dropout(dropout_rate, name=\"top_dropout\")(model)\n    model = layers.Dense(NUM_CLASSES, activation = \"softmax\")(model)\n    model = models.Model(conv_base.input, model)\n\n    model.compile(optimizer = Adam(lr = 0.01),\n                  loss = \"sparse_categorical_crossentropy\",\n                  metrics = [\"accuracy\"])\n    return model\n\nmodel = create_model()\n#model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:08.273220Z","iopub.execute_input":"2022-06-26T03:47:08.273592Z","iopub.status.idle":"2022-06-26T03:47:11.602232Z","shell.execute_reply.started":"2022-06-26T03:47:08.273539Z","shell.execute_reply":"2022-06-26T03:47:11.601162Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"epochs = 15\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n  callbacks=[model_save, early_stop, reduce_lr],\n  verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:45.379393Z","iopub.execute_input":"2022-06-26T03:47:45.379746Z","iopub.status.idle":"2022-06-26T03:56:02.826696Z","shell.execute_reply.started":"2022-06-26T03:47:45.379714Z","shell.execute_reply":"2022-06-26T03:56:02.825810Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"plot_hist(history)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:56:57.910853Z","iopub.execute_input":"2022-06-26T03:56:57.911218Z","iopub.status.idle":"2022-06-26T03:56:58.230178Z","shell.execute_reply.started":"2022-06-26T03:56:57.911182Z","shell.execute_reply":"2022-06-26T03:56:58.229220Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"# UNFREEZE (FINE-Tuning)","metadata":{}},{"cell_type":"markdown","source":"**This strategy is based on not\nonly replace the classifier layer of the network, but also retrain part or the whole network. Through backpropagation\nwe can modify the weights of the pre-trained model to adapt\nthe model to the new data distribution. Sometimes its preferable to keep the first layers of the network fixed (or freezed)\nto avoid overfitting, and only fine-tune the deeper part. This\nis motivated because the lower layers of the networks capture generic features, that are similar to many tasks while the\nhigher layers contain features that are task and dataset oriented.**","metadata":{}},{"cell_type":"code","source":"weights_path = './last_finetune_weights.h5'\nmodel.save_weights(weights_path)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:58:36.896352Z","iopub.execute_input":"2022-06-26T03:58:36.896854Z","iopub.status.idle":"2022-06-26T03:58:37.170446Z","shell.execute_reply.started":"2022-06-26T03:58:36.896788Z","shell.execute_reply":"2022-06-26T03:58:37.169570Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"### Unfreeze 100 layers","metadata":{}},{"cell_type":"code","source":"NUM_UNFREEZE_LAYERS = 100\n\nlast_model = tf.keras.models.clone_model(model)\nlast_model.load_weights(weights_path)\n\ndef unfreeze_model(model):\n    # We unfreeze the top NUM_UNFREEZE_LAYERS layers while leaving BatchNorm layers frozen\n    for layer in model.layers[-NUM_UNFREEZE_LAYERS:]:\n        if not isinstance(layer, layers.BatchNormalization):\n            layer.trainable = True\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n    model.compile(\n        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", \n        metrics=[\"accuracy\"]\n    )\n\n\nunfreeze_model(last_model)\n#cont_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:59:44.015637Z","iopub.execute_input":"2022-06-26T03:59:44.016223Z","iopub.status.idle":"2022-06-26T03:59:45.743726Z","shell.execute_reply.started":"2022-06-26T03:59:44.016183Z","shell.execute_reply":"2022-06-26T03:59:45.742854Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"epochs = 30\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n  callbacks=[model_save, early_stop, reduce_lr],\n  verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:59:59.361034Z","iopub.execute_input":"2022-06-26T03:59:59.361414Z","iopub.status.idle":"2022-06-26T04:07:41.551142Z","shell.execute_reply.started":"2022-06-26T03:59:59.361382Z","shell.execute_reply":"2022-06-26T04:07:41.550093Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"plot_hist(history)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T04:09:09.433304Z","iopub.execute_input":"2022-06-26T04:09:09.433934Z","iopub.status.idle":"2022-06-26T04:09:09.760155Z","shell.execute_reply.started":"2022-06-26T04:09:09.433897Z","shell.execute_reply":"2022-06-26T04:09:09.759192Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"### Validation Accuracy is around 73 %","metadata":{}},{"cell_type":"markdown","source":"### Unfreeze ALL layers","metadata":{}},{"cell_type":"code","source":"all_model = tf.keras.models.clone_model(model)\nall_model.load_weights(weights_path)\n\ndef fix_all(model):\n    # We unfreeze the whole layers while leaving BatchNorm layers frozen\n    for layer in model.layers:\n        if not isinstance(layer, layers.BatchNormalization):\n            layer.trainable = True\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n    model.compile(\n        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", \n        metrics=[\"accuracy\"]\n    )\n\n\nfix_all(all_model)\n#fix_all.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T04:11:43.651450Z","iopub.execute_input":"2022-06-26T04:11:43.651890Z","iopub.status.idle":"2022-06-26T04:11:45.429826Z","shell.execute_reply.started":"2022-06-26T04:11:43.651849Z","shell.execute_reply":"2022-06-26T04:11:45.428874Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"epochs = 15  # @param {type: \"slider\", min:8, max:50}\nhistory = all_model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs,\n  callbacks=[model_save, early_stop, reduce_lr],\n  verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T04:13:24.165593Z","iopub.execute_input":"2022-06-26T04:13:24.165967Z","iopub.status.idle":"2022-06-26T04:37:20.528812Z","shell.execute_reply.started":"2022-06-26T04:13:24.165933Z","shell.execute_reply":"2022-06-26T04:37:20.527995Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"plot_hist(history)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T04:37:20.533239Z","iopub.execute_input":"2022-06-26T04:37:20.533969Z","iopub.status.idle":"2022-06-26T04:37:20.868962Z","shell.execute_reply.started":"2022-06-26T04:37:20.533924Z","shell.execute_reply":"2022-06-26T04:37:20.867882Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**--> Range of 76% accuracy is achieved after Unfreeze all of the layers**","metadata":{}},{"cell_type":"markdown","source":"**--> Although there is an increasing in validation accuracy,the problem of overfitting still appears as a result of lack training data.**","metadata":{}},{"cell_type":"markdown","source":"**--> Ordinary data augmentation may not be feasible for song data like GTZAN, because:**\n*      Cannot use typical transformations like rotation, zoom, flipping because spectrogram would be non-sense\n*      Cannot use audio transformation because this will distort the original song.**","metadata":{}},{"cell_type":"markdown","source":"### Useful Links\n- https://www.tensorflow.org/tutorials/images/classification\n- https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/","metadata":{}}]}